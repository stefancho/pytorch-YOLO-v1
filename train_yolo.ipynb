{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eginpcF4Qll7"
   },
   "source": [
    "### Download VOC 2007 and save it to locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-nvMdsd50w3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_path = os.getcwd()\n",
    "root_dir = '/content/data'\n",
    "data_exist = False\n",
    "\n",
    "try:\n",
    "  os.mkdir('/content')\n",
    "  os.mkdir(root_dir) \n",
    "  os.chdir(root_dir) \n",
    "except:\n",
    "  data_exist = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362253
    },
    "colab_type": "code",
    "id": "B5eIuV5FoHyI",
    "outputId": "12cff72b-d5c9-4ae4-ec4f-9f49a53818d9"
   },
   "outputs": [],
   "source": [
    "if not data_exist:\n",
    "  !curl -LO \"https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\"\n",
    "  !curl -LO \"https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\"\n",
    "  !curl -LO \"https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtrainval_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtest_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtrainval_11-May-2012.tar\"\n",
    "  !rm \"VOCtrainval_06-Nov-2007.tar\"\n",
    "  !rm \"VOCtest_06-Nov-2007.tar\"\n",
    "  !rm \"VOCtrainval_11-May-2012.tar\"  \n",
    "  !sudo mv /content/data/VOCdevkit/VOC2012/JPEGImages/ /content/data/VOCdevkit/VOC2012/allimages/\n",
    "#   !sudo mv /content/data/VOCdevkit/VOC2007/JPEGImages /content/data/VOCdevkit/VOC2012/allimages/\n",
    "  !cp /content/data/VOCdevkit/VOC2007/JPEGImages/* /content/data/VOCdevkit/VOC2012/allimages/\n",
    "  !rm /content/data/VOCdevkit/VOC2007/JPEGImages/*.jpg\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YslcQuEs3_it"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from net import vgg16, vgg16_bn\n",
    "from resnet_yolo import resnet50, resnet18\n",
    "from yoloLoss import YoloLoss\n",
    "from dataset import yoloDataset\n",
    "\n",
    "from visualizer import Visualizer\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WsPuKcB3_iz"
   },
   "outputs": [],
   "source": [
    "use_local = os.path.exists('/home/stefan/data/VOCdevkit/VOC2007')\n",
    "\n",
    "file_root = '/home/stefan/data/VOCdevkit/VOC2007/JPEGImages' if use_local else root_dir +  '/VOCdevkit/VOC2012/allimages/'\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 24\n",
    "use_resnet = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if use_resnet:\n",
    "    net = resnet50()\n",
    "else:\n",
    "    net = vgg16_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10914
    },
    "colab_type": "code",
    "id": "aRxk9iz-CRzK",
    "outputId": "eb5189bc-5a14-4755-e253-3c827673b14f"
   },
   "outputs": [],
   "source": [
    "print('load pre-trined model')\n",
    "if use_resnet:\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    new_state_dict = resnet.state_dict()\n",
    "    dd = net.state_dict()\n",
    "    for k in new_state_dict.keys():\n",
    "        print(k)\n",
    "        if k in dd.keys() and not k.startswith('fc'):\n",
    "            print('yes')\n",
    "            dd[k] = new_state_dict[k]\n",
    "    net.load_state_dict(dd)\n",
    "else:\n",
    "    vgg = models.vgg16_bn(pretrained=True)\n",
    "    new_state_dict = vgg.state_dict()\n",
    "    dd = net.state_dict()\n",
    "    for k in new_state_dict.keys():\n",
    "        print(k)\n",
    "        if k in dd.keys() and k.startswith('features'):\n",
    "            print('yes')\n",
    "            dd[k] = new_state_dict[k]\n",
    "    net.load_state_dict(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFGj9GV7SGqu"
   },
   "outputs": [],
   "source": [
    "criterion = YoloLoss(5,0.5)\n",
    "\n",
    "net = net.to(device)\n",
    "net.train()\n",
    "# different learning rate\n",
    "params=[]\n",
    "params_dict = dict(net.named_parameters())\n",
    "for key,value in params_dict.items():\n",
    "    if key.startswith('features'):\n",
    "        params += [{'params':[value],'lr':learning_rate*1}]\n",
    "    else:\n",
    "        params += [{'params':[value],'lr':learning_rate}]\n",
    "optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VH38QYvdQvqg"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vKT_B8mn3_jP",
    "outputId": "c3ab3560-e92e-4cdd-fd6f-7dbe273c9ce7"
   },
   "outputs": [],
   "source": [
    "if use_local:\n",
    "    train_dataset = yoloDataset(root=file_root,list_file=os.path.join(project_path, 'voc2007.txt'),train=True,transform = [transforms.ToTensor()] )\n",
    "else:\n",
    "    train_dataset = yoloDataset(root=file_root,list_file=[os.path.join(project_path, 'voc2007.txt'), os.path.join(project_path, 'voc2012.txt')],train=True,transform = [transforms.ToTensor()] )\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "# test_dataset = yoloDataset(root=file_root,list_file='voc07_test.txt',train=False,transform = [transforms.ToTensor()] )\n",
    "test_dataset = yoloDataset(root=file_root,list_file=os.path.join(project_path, 'voc2007test.txt'),train=False,transform = [transforms.ToTensor()] )\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "print('the dataset has %d images' % (len(train_dataset)))\n",
    "print('the batch_size is %d' % (batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyZXftN7QO2L"
   },
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38794
    },
    "colab_type": "code",
    "id": "0zMG38FV3_jZ",
    "outputId": "df5ba856-85b7-4ced-f2f0-df725d951ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started in 2019-05-07 20:14:08.642116\n",
      "\n",
      "\n",
      "Starting epoch 1 / 50\n",
      "Learning Rate for this epoch: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Process Process-9:\n",
      "Process Process-11:\n",
      "Process Process-12:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f18e3aa3080>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 397, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 14980) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-72f94a81c153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Started in {}\".format(datetime.datetime.now()))\n",
    "timer = time.time()\n",
    "num_iter = 0\n",
    "vis = Visualizer()\n",
    "best_test_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    if epoch == 1:\n",
    "        learning_rate = 0.0005\n",
    "    if epoch == 2:\n",
    "        learning_rate = 0.00075\n",
    "    if epoch == 3:\n",
    "        learning_rate = 0.001\n",
    "    if epoch == 30:\n",
    "        learning_rate=0.0001\n",
    "    if epoch == 40:\n",
    "        learning_rate=0.00001\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate\n",
    "    \n",
    "    print('\\n\\nStarting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "    print('Learning Rate for this epoch: {}'.format(learning_rate))\n",
    "    \n",
    "    total_loss = 0.\n",
    "    \n",
    "    for i,(images,target) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        pred = net(images)\n",
    "        loss = criterion(pred,target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 5 == 0:\n",
    "            cur_time = time.time()\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, average_loss: %.4f, time(s): %.2f' \n",
    "            %(epoch+1, num_epochs, i+1, len(train_loader), loss.item(), total_loss / (i+1), cur_time-timer))\n",
    "            num_iter += 1\n",
    "            timer = cur_time\n",
    "            vis.add_log((\"train_avrg_loss\", total_loss/(i+1)))\n",
    "    vis.add_log((\"train_loss\", total_loss / len(train_loader)), epoch)\n",
    "    \n",
    "    #validation\n",
    "    validation_loss = 0.0\n",
    "    net.eval()\n",
    "    for i,(images,target) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)     \n",
    "        with torch.set_grad_enabled(False):\n",
    "          pred = net(images)\n",
    "          loss = criterion(pred,target)\n",
    "          validation_loss += loss.item()\n",
    "    validation_loss /= len(test_loader)\n",
    "    vis.add_log((\"val_loss\", validation_loss), epoch)\n",
    "    vis.save(os.path.join(project_path, 'temp.csv'))\n",
    "    if best_test_loss > validation_loss:\n",
    "        best_test_loss = validation_loss\n",
    "        print('get best test loss %.5f' % best_test_loss)\n",
    "        torch.save(net.state_dict(),'best.pth')\n",
    "        \n",
    "\n",
    "vis.save('train_log{}.csv'.format(time.time()))\n",
    "torch.save(net.state_dict(),os.path.join(project_path, 'yolo.pth'))\n",
    "vis.plot()\n",
    "print(\"Ended in {}\".format(datetime.datetime.now()))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_yolo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
