{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eginpcF4Qll7"
   },
   "source": [
    "### Download VOC 2007 and save it to locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-nvMdsd50w3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_path = os.getcwd()\n",
    "root_dir = '/content/data'\n",
    "data_exist = False\n",
    "\n",
    "try:\n",
    "  os.mkdir('/content')\n",
    "  os.mkdir(root_dir) \n",
    "  os.chdir(root_dir) \n",
    "except:\n",
    "  data_exist = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362253
    },
    "colab_type": "code",
    "id": "B5eIuV5FoHyI",
    "outputId": "12cff72b-d5c9-4ae4-ec4f-9f49a53818d9"
   },
   "outputs": [],
   "source": [
    "if not data_exist:\n",
    "  !curl -LO \"https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\"\n",
    "  !curl -LO \"https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\"\n",
    "  !curl -LO \"https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtrainval_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtest_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtrainval_11-May-2012.tar\"\n",
    "  !rm \"VOCtrainval_06-Nov-2007.tar\"\n",
    "  !rm \"VOCtest_06-Nov-2007.tar\"\n",
    "  !rm \"VOCtrainval_11-May-2012.tar\"  \n",
    "  !sudo mv /content/data/VOCdevkit/VOC2012/JPEGImages/ /content/data/VOCdevkit/VOC2012/allimages/\n",
    "#   !sudo mv /content/data/VOCdevkit/VOC2007/JPEGImages /content/data/VOCdevkit/VOC2012/allimages/\n",
    "  !cp /content/data/VOCdevkit/VOC2007/JPEGImages/* /content/data/VOCdevkit/VOC2012/allimages/\n",
    "  !rm /content/data/VOCdevkit/VOC2007/JPEGImages/*.jpg\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-06 19:43:20.556345\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch modified_yolo\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   dataset.py\u001b[m\r\n",
      "\t\u001b[31mmodified:   resnet_yolo.py\u001b[m\r\n",
      "\t\u001b[31mmodified:   train_yolo.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mbest_prev.pth\u001b[m\r\n",
      "\t\u001b[31meval_loc.ipynb\u001b[m\r\n",
      "\t\u001b[31mmulti_loss.py\u001b[m\r\n",
      "\t\u001b[31mtemp.csv\u001b[m\r\n",
      "\t\u001b[31mtest_loss.ipynb\u001b[m\r\n",
      "\t\u001b[31mtrain_log.csv\u001b[m\r\n",
      "\t\u001b[31mvisualize_logs.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YslcQuEs3_it"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from net import vgg16, vgg16_bn\n",
    "from resnet_yolo import resnet50, resnet18\n",
    "from yoloLoss import YoloLoss\n",
    "from multi_loss import MultiLoss\n",
    "from dataset import yoloDataset\n",
    "\n",
    "from visualizer import Visualizer\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WsPuKcB3_iz"
   },
   "outputs": [],
   "source": [
    "use_local = os.path.exists('/home/stefan/data/VOCdevkit/VOC2007')\n",
    "\n",
    "file_root = '/home/stefan/data/VOCdevkit/VOC2007/JPEGImages' if use_local else root_dir +  '/VOCdevkit/VOC2012/allimages/'\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 1\n",
    "use_resnet = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if use_resnet:\n",
    "    net = resnet18()\n",
    "else:\n",
    "    net = vgg16_bn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10914
    },
    "colab_type": "code",
    "id": "aRxk9iz-CRzK",
    "outputId": "eb5189bc-5a14-4755-e253-3c827673b14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pre-trined model\n",
      "conv1.weight\n",
      "yes\n",
      "bn1.weight\n",
      "yes\n",
      "bn1.bias\n",
      "yes\n",
      "bn1.running_mean\n",
      "yes\n",
      "bn1.running_var\n",
      "yes\n",
      "bn1.num_batches_tracked\n",
      "yes\n",
      "layer1.0.conv1.weight\n",
      "yes\n",
      "layer1.0.bn1.weight\n",
      "yes\n",
      "layer1.0.bn1.bias\n",
      "yes\n",
      "layer1.0.bn1.running_mean\n",
      "yes\n",
      "layer1.0.bn1.running_var\n",
      "yes\n",
      "layer1.0.bn1.num_batches_tracked\n",
      "yes\n",
      "layer1.0.conv2.weight\n",
      "yes\n",
      "layer1.0.bn2.weight\n",
      "yes\n",
      "layer1.0.bn2.bias\n",
      "yes\n",
      "layer1.0.bn2.running_mean\n",
      "yes\n",
      "layer1.0.bn2.running_var\n",
      "yes\n",
      "layer1.0.bn2.num_batches_tracked\n",
      "yes\n",
      "layer1.1.conv1.weight\n",
      "yes\n",
      "layer1.1.bn1.weight\n",
      "yes\n",
      "layer1.1.bn1.bias\n",
      "yes\n",
      "layer1.1.bn1.running_mean\n",
      "yes\n",
      "layer1.1.bn1.running_var\n",
      "yes\n",
      "layer1.1.bn1.num_batches_tracked\n",
      "yes\n",
      "layer1.1.conv2.weight\n",
      "yes\n",
      "layer1.1.bn2.weight\n",
      "yes\n",
      "layer1.1.bn2.bias\n",
      "yes\n",
      "layer1.1.bn2.running_mean\n",
      "yes\n",
      "layer1.1.bn2.running_var\n",
      "yes\n",
      "layer1.1.bn2.num_batches_tracked\n",
      "yes\n",
      "layer2.0.conv1.weight\n",
      "yes\n",
      "layer2.0.bn1.weight\n",
      "yes\n",
      "layer2.0.bn1.bias\n",
      "yes\n",
      "layer2.0.bn1.running_mean\n",
      "yes\n",
      "layer2.0.bn1.running_var\n",
      "yes\n",
      "layer2.0.bn1.num_batches_tracked\n",
      "yes\n",
      "layer2.0.conv2.weight\n",
      "yes\n",
      "layer2.0.bn2.weight\n",
      "yes\n",
      "layer2.0.bn2.bias\n",
      "yes\n",
      "layer2.0.bn2.running_mean\n",
      "yes\n",
      "layer2.0.bn2.running_var\n",
      "yes\n",
      "layer2.0.bn2.num_batches_tracked\n",
      "yes\n",
      "layer2.0.downsample.0.weight\n",
      "yes\n",
      "layer2.0.downsample.1.weight\n",
      "yes\n",
      "layer2.0.downsample.1.bias\n",
      "yes\n",
      "layer2.0.downsample.1.running_mean\n",
      "yes\n",
      "layer2.0.downsample.1.running_var\n",
      "yes\n",
      "layer2.0.downsample.1.num_batches_tracked\n",
      "yes\n",
      "layer2.1.conv1.weight\n",
      "yes\n",
      "layer2.1.bn1.weight\n",
      "yes\n",
      "layer2.1.bn1.bias\n",
      "yes\n",
      "layer2.1.bn1.running_mean\n",
      "yes\n",
      "layer2.1.bn1.running_var\n",
      "yes\n",
      "layer2.1.bn1.num_batches_tracked\n",
      "yes\n",
      "layer2.1.conv2.weight\n",
      "yes\n",
      "layer2.1.bn2.weight\n",
      "yes\n",
      "layer2.1.bn2.bias\n",
      "yes\n",
      "layer2.1.bn2.running_mean\n",
      "yes\n",
      "layer2.1.bn2.running_var\n",
      "yes\n",
      "layer2.1.bn2.num_batches_tracked\n",
      "yes\n",
      "layer3.0.conv1.weight\n",
      "yes\n",
      "layer3.0.bn1.weight\n",
      "yes\n",
      "layer3.0.bn1.bias\n",
      "yes\n",
      "layer3.0.bn1.running_mean\n",
      "yes\n",
      "layer3.0.bn1.running_var\n",
      "yes\n",
      "layer3.0.bn1.num_batches_tracked\n",
      "yes\n",
      "layer3.0.conv2.weight\n",
      "yes\n",
      "layer3.0.bn2.weight\n",
      "yes\n",
      "layer3.0.bn2.bias\n",
      "yes\n",
      "layer3.0.bn2.running_mean\n",
      "yes\n",
      "layer3.0.bn2.running_var\n",
      "yes\n",
      "layer3.0.bn2.num_batches_tracked\n",
      "yes\n",
      "layer3.0.downsample.0.weight\n",
      "yes\n",
      "layer3.0.downsample.1.weight\n",
      "yes\n",
      "layer3.0.downsample.1.bias\n",
      "yes\n",
      "layer3.0.downsample.1.running_mean\n",
      "yes\n",
      "layer3.0.downsample.1.running_var\n",
      "yes\n",
      "layer3.0.downsample.1.num_batches_tracked\n",
      "yes\n",
      "layer3.1.conv1.weight\n",
      "yes\n",
      "layer3.1.bn1.weight\n",
      "yes\n",
      "layer3.1.bn1.bias\n",
      "yes\n",
      "layer3.1.bn1.running_mean\n",
      "yes\n",
      "layer3.1.bn1.running_var\n",
      "yes\n",
      "layer3.1.bn1.num_batches_tracked\n",
      "yes\n",
      "layer3.1.conv2.weight\n",
      "yes\n",
      "layer3.1.bn2.weight\n",
      "yes\n",
      "layer3.1.bn2.bias\n",
      "yes\n",
      "layer3.1.bn2.running_mean\n",
      "yes\n",
      "layer3.1.bn2.running_var\n",
      "yes\n",
      "layer3.1.bn2.num_batches_tracked\n",
      "yes\n",
      "layer4.0.conv1.weight\n",
      "yes\n",
      "layer4.0.bn1.weight\n",
      "yes\n",
      "layer4.0.bn1.bias\n",
      "yes\n",
      "layer4.0.bn1.running_mean\n",
      "yes\n",
      "layer4.0.bn1.running_var\n",
      "yes\n",
      "layer4.0.bn1.num_batches_tracked\n",
      "yes\n",
      "layer4.0.conv2.weight\n",
      "yes\n",
      "layer4.0.bn2.weight\n",
      "yes\n",
      "layer4.0.bn2.bias\n",
      "yes\n",
      "layer4.0.bn2.running_mean\n",
      "yes\n",
      "layer4.0.bn2.running_var\n",
      "yes\n",
      "layer4.0.bn2.num_batches_tracked\n",
      "yes\n",
      "layer4.0.downsample.0.weight\n",
      "yes\n",
      "layer4.0.downsample.1.weight\n",
      "yes\n",
      "layer4.0.downsample.1.bias\n",
      "yes\n",
      "layer4.0.downsample.1.running_mean\n",
      "yes\n",
      "layer4.0.downsample.1.running_var\n",
      "yes\n",
      "layer4.0.downsample.1.num_batches_tracked\n",
      "yes\n",
      "layer4.1.conv1.weight\n",
      "yes\n",
      "layer4.1.bn1.weight\n",
      "yes\n",
      "layer4.1.bn1.bias\n",
      "yes\n",
      "layer4.1.bn1.running_mean\n",
      "yes\n",
      "layer4.1.bn1.running_var\n",
      "yes\n",
      "layer4.1.bn1.num_batches_tracked\n",
      "yes\n",
      "layer4.1.conv2.weight\n",
      "yes\n",
      "layer4.1.bn2.weight\n",
      "yes\n",
      "layer4.1.bn2.bias\n",
      "yes\n",
      "layer4.1.bn2.running_mean\n",
      "yes\n",
      "layer4.1.bn2.running_var\n",
      "yes\n",
      "layer4.1.bn2.num_batches_tracked\n",
      "yes\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "print('load pre-trined model')\n",
    "if use_resnet:\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    new_state_dict = resnet.state_dict()\n",
    "    dd = net.state_dict()\n",
    "    for k in new_state_dict.keys():\n",
    "        print(k)\n",
    "        if k in dd.keys() and not k.startswith('fc'):\n",
    "            print('yes')\n",
    "            dd[k] = new_state_dict[k]\n",
    "    net.load_state_dict(dd)\n",
    "else:\n",
    "    vgg = models.vgg16_bn(pretrained=True)\n",
    "    new_state_dict = vgg.state_dict()\n",
    "    dd = net.state_dict()\n",
    "    for k in new_state_dict.keys():\n",
    "        print(k)\n",
    "        if k in dd.keys() and k.startswith('features'):\n",
    "            print('yes')\n",
    "            dd[k] = new_state_dict[k]\n",
    "    net.load_state_dict(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFGj9GV7SGqu"
   },
   "outputs": [],
   "source": [
    "# criterion = YoloLoss(5,0.5)\n",
    "criterion = MultiLoss(5,0.5)\n",
    "\n",
    "net = net.to(device)\n",
    "net.train()\n",
    "# different learning rate\n",
    "params=[]\n",
    "params_dict = dict(net.named_parameters())\n",
    "for key,value in params_dict.items():\n",
    "    if key.startswith('features'):\n",
    "        params += [{'params':[value],'lr':learning_rate*1}]\n",
    "    else:\n",
    "        params += [{'params':[value],'lr':learning_rate}]\n",
    "optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VH38QYvdQvqg"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vKT_B8mn3_jP",
    "outputId": "c3ab3560-e92e-4cdd-fd6f-7dbe273c9ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data init\n",
      "data init\n",
      "the dataset has 5012 images\n",
      "the batch_size is 1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = yoloDataset(root=file_root,list_file=os.path.join(project_path, 'voc2007.txt'),train=True,transform = [transforms.ToTensor()] )\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "# test_dataset = yoloDataset(root=file_root,list_file='voc07_test.txt',train=False,transform = [transforms.ToTensor()] )\n",
    "test_dataset = yoloDataset(root=file_root,list_file=os.path.join(project_path, 'voc2007test.txt'),train=False,transform = [transforms.ToTensor()] )\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "print('the dataset has %d images' % (len(train_dataset)))\n",
    "print('the batch_size is %d' % (batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyZXftN7QO2L"
   },
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38794
    },
    "colab_type": "code",
    "id": "0zMG38FV3_jZ",
    "outputId": "df5ba856-85b7-4ced-f2f0-df725d951ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 1 / 50\n",
      "Learning Rate for this epoch: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [5/5012] Loss: 58.7172, average_loss: 62.1232, time(s): 8.04\n",
      "Epoch [1/50], Iter [10/5012] Loss: 39.0382, average_loss: 55.4229, time(s): 6.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Process Process-10:\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0ee79debcdcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python/ML/pytorch-YOLO-v1/resnet_yolo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python/ML/pytorch-YOLO-v1/resnet_yolo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/ssd/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/stefan/programs/anaconda3/envs/ssd/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "timer = time.time()\n",
    "num_iter = 0\n",
    "vis = Visualizer()\n",
    "best_test_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    if epoch == 1:\n",
    "        learning_rate = 0.0005\n",
    "    if epoch == 2:\n",
    "        learning_rate = 0.00075\n",
    "    if epoch == 3:\n",
    "        learning_rate = 0.001\n",
    "    if epoch == 30:\n",
    "        learning_rate=0.0001\n",
    "    if epoch == 40:\n",
    "        learning_rate=0.00001\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate\n",
    "    \n",
    "    print('\\n\\nStarting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "    print('Learning Rate for this epoch: {}'.format(learning_rate))\n",
    "    \n",
    "    total_loss = 0.\n",
    "    \n",
    "    for i,(images,target) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        pred = net(images)\n",
    "        loss = criterion(pred,target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 5 == 0:\n",
    "            cur_time = time.time()\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, average_loss: %.4f, time(s): %.2f' \n",
    "            %(epoch+1, num_epochs, i+1, len(train_loader), loss.item(), total_loss / (i+1), cur_time-timer))\n",
    "            num_iter += 1\n",
    "            timer = cur_time\n",
    "            vis.add_log((\"train_avrg_loss\", total_loss/(i+1)))\n",
    "    vis.add_log((\"train_loss\", total_loss / len(train_loader)), epoch)\n",
    "    \n",
    "    #validation\n",
    "    validation_loss = 0.0\n",
    "    net.eval()\n",
    "    for i,(images,target) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)     \n",
    "        with torch.set_grad_enabled(False):\n",
    "          pred = net(images)\n",
    "          loss = criterion(pred,target)\n",
    "          validation_loss += loss.item()\n",
    "    validation_loss /= len(test_loader)\n",
    "    vis.add_log((\"val_loss\", validation_loss), epoch)\n",
    "    vis.save(os.path.join(project_path, 'temp.csv'))\n",
    "    if best_test_loss > validation_loss:\n",
    "        best_test_loss = validation_loss\n",
    "        print('get best test loss %.5f' % best_test_loss)\n",
    "        torch.save(net.state_dict(),'best.pth')\n",
    "        \n",
    "\n",
    "vis.save('train_log{}.csv'.format(time.time()))\n",
    "torch.save(net.state_dict(),os.path.join(project_path, 'yolo.pth'))\n",
    "vis.plot()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_yolo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
