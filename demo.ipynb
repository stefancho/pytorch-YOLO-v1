{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YslcQuEs3_it"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import cv2\n",
    "from resnet_yolo import resnet50, resnet18\n",
    "import torchvision.transforms as transforms\n",
    "from dataset import yoloDataset\n",
    "from predict import *\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from visualize import Visualizer\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WsPuKcB3_iz"
   },
   "outputs": [],
   "source": [
    "\n",
    "file_root = '/home/stefan/data/VOCdevkit/VOC2007/JPEGImages/'\n",
    "project_path = os.getcwd()\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 24\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10914
    },
    "colab_type": "code",
    "id": "aRxk9iz-CRzK",
    "outputId": "eb5189bc-5a14-4755-e253-3c827673b14f"
   },
   "outputs": [],
   "source": [
    "net = resnet50()\n",
    "print('load model...')\n",
    "net.load_state_dict(torch.load('best.pth', map_location='cpu'))\n",
    "net = net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VH38QYvdQvqg"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vKT_B8mn3_jP",
    "outputId": "c3ab3560-e92e-4cdd-fd6f-7dbe273c9ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data init\n"
     ]
    }
   ],
   "source": [
    "train_dataset = yoloDataset(root=file_root,list_file=os.path.join(project_path, 'voc2007.txt'),train=False,transform = [transforms.ToTensor()] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'dog.jpg'\n",
    "image = cv2.imread(image_name)\n",
    "print('predicting...')\n",
    "result = predict_img(net, image_name, device)\n",
    "for left_up,right_bottom,class_name,_,prob in result:\n",
    "    color = Color[VOC_CLASSES.index(class_name)]\n",
    "    cv2.rectangle(image,left_up,right_bottom,color,2)\n",
    "    label = class_name+str(round(prob,2))\n",
    "    text_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "    p1 = (left_up[0], left_up[1]- text_size[1])\n",
    "    cv2.rectangle(image, (p1[0] - 2//2, p1[1] - 2 - baseline), (p1[0] + text_size[0], p1[1] + text_size[1]), color, -1)\n",
    "    cv2.putText(image, label, (p1[0], p1[1] + baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, 8)\n",
    "\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# View the sampled input image before transform\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(rgb_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_idx = 234\n",
    "\n",
    "img, _ = train_dataset[image_idx]\n",
    "image = train_dataset.pull_img(image_idx)\n",
    "\n",
    "\n",
    "# image_name = 'person.jpg'\n",
    "# image = cv2.imread(image_name)\n",
    "print('predicting...')\n",
    "result = predict(net, img, device)\n",
    "for left_up,right_bottom,class_name,_,prob in result:\n",
    "    color = Color[VOC_CLASSES.index(class_name)]\n",
    "    cv2.rectangle(image,left_up,right_bottom,color,2)\n",
    "    label = class_name+str(round(prob,2))\n",
    "    text_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "    p1 = (left_up[0], left_up[1]- text_size[1])\n",
    "    cv2.rectangle(image, (p1[0] - 2//2, p1[1] - 2 - baseline), (p1[0] + text_size[0], p1[1] + text_size[1]), color, -1)\n",
    "    cv2.putText(image, label, (p1[0], p1[1] + baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, 8)\n",
    "    \n",
    "    print(\"box[{}, {}] -> {}\".format(left_up, right_bottom, class_name))\n",
    "    \n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# View the sampled input image before transform\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(rgb_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_yolo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
